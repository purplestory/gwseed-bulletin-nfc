#!/usr/bin/env python3
"""
ì •ê¸°ì ìœ¼ë¡œ ìµœì‹  ì£¼ë³´ë¥¼ í™•ì¸í•˜ê³  ìë™ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""

import sqlite3
import requests
from bs4 import BeautifulSoup
import re
from datetime import datetime
import json
import os

def get_latest_bulletin_from_website():
    """êµíšŒ ì›¹ì‚¬ì´íŠ¸ì—ì„œ ìµœì‹  ì£¼ë³´ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
    try:
        url = "https://www.godswillseed.or.kr/bbs/board.php?bo_table=weekly"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
        
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # ìµœì‹  ì£¼ë³´ ë§í¬ ì°¾ê¸° (ê³µì§€ê°€ ì•„ë‹Œ ì¼ë°˜ ê²Œì‹œë¬¼)
        latest_post = None
        for post in soup.select("tbody tr:not(.bo_notice)"):
            link_tag = post.select_one("td.td_subject a")
            if link_tag and 'href' in link_tag.attrs:
                href = str(link_tag['href'])
                if 'wr_id=' in href and 'weekly' in href:
                    if not href.startswith('http'):
                        href = "https://www.godswillseed.or.kr" + href
                    
                    # wr_id ì¶”ì¶œ
                    wr_id_match = re.search(r'wr_id=(\d+)', href)
                    wr_id = wr_id_match.group(1) if wr_id_match else None
                    
                    # ì œëª© ì¶”ì¶œ
                    title = link_tag.get_text(strip=True)
                    
                    latest_post = {
                        'url': href,
                        'wr_id': wr_id,
                        'title': title,
                        'timestamp': datetime.now().isoformat()
                    }
                    break
        
        return latest_post
        
    except Exception as e:
        print(f"ìµœì‹  ì£¼ë³´ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        return None

def get_latest_bulletin_from_db():
    """ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ìµœì‹  ì£¼ë³´ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
    conn = sqlite3.connect('weekly_posts.db')
    cursor = conn.cursor()
    
    try:
        cursor.execute("SELECT wr_id, title FROM weekly_posts ORDER BY wr_id DESC LIMIT 1")
        result = cursor.fetchone()
        
        if result:
            return {
                'wr_id': result[0],
                'title': result[1]
            }
        return None
        
    except Exception as e:
        print(f"ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ìµœì‹  ì£¼ë³´ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        return None
    finally:
        conn.close()

def add_new_bulletin_to_db(bulletin_info):
    """ìƒˆë¡œìš´ ì£¼ë³´ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì¶”ê°€"""
    conn = sqlite3.connect('weekly_posts.db')
    cursor = conn.cursor()
    
    try:
        wr_id = bulletin_info['wr_id']
        title = bulletin_info['title']
        url = bulletin_info['url']
        
        # ë‚ ì§œ ì¶”ì¶œ
        date_match = re.search(r'(\d{4})ë…„\s*(\d{1,2})ì›”\s*(\d{1,2})ì¼', title)
        if date_match:
            year, month, day = date_match.groups()
            post_date = f"{year}-{month.zfill(2)}-{day.zfill(2)}"
        else:
            post_date = datetime.now().strftime("%Y-%m-%d")
        
        # ë°ì´í„°ë² ì´ìŠ¤ì— ì‚½ì…
        cursor.execute("""
            INSERT INTO weekly_posts (wr_id, title, url, created_at, image_paths, ocr_data)
            VALUES (?, ?, ?, ?, '', '')
        """, (wr_id, title, url, post_date))
        
        conn.commit()
        print(f"âœ… ìƒˆë¡œìš´ ì£¼ë³´ê°€ ë°ì´í„°ë² ì´ìŠ¤ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤: {title}")
        return True
        
    except Exception as e:
        print(f"âŒ ì£¼ë³´ ì¶”ê°€ ì‹¤íŒ¨: {e}")
        conn.rollback()
        return False
    finally:
        conn.close()

def update_latest_bulletin_file(bulletin_info):
    """ìµœì‹  ì£¼ë³´ ì •ë³´ë¥¼ íŒŒì¼ì— ì €ì¥"""
    try:
        with open('latest_bulletin.json', 'w', encoding='utf-8') as f:
            json.dump(bulletin_info, f, ensure_ascii=False, indent=2)
        print(f"âœ… ìµœì‹  ì£¼ë³´ ì •ë³´ íŒŒì¼ ì—…ë°ì´íŠ¸: {bulletin_info['title']}")
        return True
    except Exception as e:
        print(f"âŒ íŒŒì¼ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def check_and_update_latest_bulletin():
    """ìµœì‹  ì£¼ë³´ í™•ì¸ ë° ì—…ë°ì´íŠ¸"""
    print("ğŸ” êµíšŒ ì›¹ì‚¬ì´íŠ¸ì—ì„œ ìµœì‹  ì£¼ë³´ í™•ì¸ ì¤‘...")
    
    # ì›¹ì‚¬ì´íŠ¸ì—ì„œ ìµœì‹  ì£¼ë³´ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    website_latest = get_latest_bulletin_from_website()
    if not website_latest:
        print("âŒ ì›¹ì‚¬ì´íŠ¸ì—ì„œ ìµœì‹  ì£¼ë³´ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False
    
    print(f"ğŸ“‹ ì›¹ì‚¬ì´íŠ¸ ìµœì‹  ì£¼ë³´: {website_latest['title']} (wr_id: {website_latest['wr_id']})")
    
    # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ìµœì‹  ì£¼ë³´ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    db_latest = get_latest_bulletin_from_db()
    if db_latest:
        print(f"ğŸ“‹ ë°ì´í„°ë² ì´ìŠ¤ ìµœì‹  ì£¼ë³´: {db_latest['title']} (wr_id: {db_latest['wr_id']})")
    else:
        print("ğŸ“‹ ë°ì´í„°ë² ì´ìŠ¤ì— ì£¼ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # ìƒˆë¡œìš´ ì£¼ë³´ì¸ì§€ í™•ì¸
    if not db_latest or int(website_latest['wr_id']) > int(db_latest['wr_id']):
        print("ğŸ†• ìƒˆë¡œìš´ ì£¼ë³´ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤!")
        
        # ë°ì´í„°ë² ì´ìŠ¤ì— ì¶”ê°€
        if add_new_bulletin_to_db(website_latest):
            # ìµœì‹  ì£¼ë³´ ì •ë³´ íŒŒì¼ ì—…ë°ì´íŠ¸
            update_latest_bulletin_file(website_latest)
            
            print("ğŸ‰ ìƒˆë¡œìš´ ì£¼ë³´ê°€ ì„±ê³µì ìœ¼ë¡œ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!")
            print("ğŸ“ ë‹¤ìŒ ë‹¨ê³„: scraper.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° OCR ì²˜ë¦¬ë¥¼ ì§„í–‰í•˜ì„¸ìš”.")
            return True
        else:
            print("âŒ ìƒˆë¡œìš´ ì£¼ë³´ ì¶”ê°€ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return False
    else:
        print("âœ… ì´ë¯¸ ìµœì‹  ì£¼ë³´ê°€ ë°ì´í„°ë² ì´ìŠ¤ì— ìˆìŠµë‹ˆë‹¤.")
        # ìµœì‹  ì£¼ë³´ ì •ë³´ íŒŒì¼ ì—…ë°ì´íŠ¸
        update_latest_bulletin_file(website_latest)
        return True

if __name__ == "__main__":
    check_and_update_latest_bulletin() 