#!/usr/bin/env python3
"""
ì •ê¸°ì ìœ¼ë¡œ ìµœì‹  ì£¼ë³´ë¥¼ í™•ì¸í•˜ê³  ìë™ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
ë§¤ì£¼ ì¼ìš”ì¼ ì˜¤ì „ 9ì‹œì— ì‹¤í–‰ë˜ë„ë¡ cron job ì„¤ì •
"""

import requests
from bs4 import BeautifulSoup
import re
import json
import os
from datetime import datetime
import subprocess

def get_latest_bulletin():
    """êµíšŒ ì›¹ì‚¬ì´íŠ¸ì—ì„œ ìµœì‹  ì£¼ë³´ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
    try:
        url = "https://www.godswillseed.or.kr/bbs/board.php?bo_table=weekly"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
        
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # ìµœì‹  ì£¼ë³´ ë§í¬ ì°¾ê¸°
        all_links = soup.find_all('a', href=True)
        weekly_links = []
        
        for link in all_links:
            href = str(link.get('href', ''))
            if 'wr_id=' in href and 'weekly' in href:
                weekly_links.append(href)
        
        if weekly_links:
            latest_link = weekly_links[0]
            if not latest_link.startswith('http'):
                latest_link = "https://www.godswillseed.or.kr" + latest_link
            
            # wr_id ì¶”ì¶œ
            wr_id_match = re.search(r'wr_id=(\d+)', latest_link)
            wr_id = wr_id_match.group(1) if wr_id_match else None
            
            return {
                'url': latest_link,
                'wr_id': wr_id,
                'timestamp': datetime.now().isoformat()
            }
        
        return None
        
    except Exception as e:
        print(f"ìµœì‹  ì£¼ë³´ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        return None

def update_index_html(wr_id):
    """index.html íŒŒì¼ì—ì„œ wr_id ì—…ë°ì´íŠ¸"""
    try:
        # index.html íŒŒì¼ ì½ê¸°
        with open('index.html', 'r', encoding='utf-8') as f:
            content = f.read()
        
        # wr_id ì—…ë°ì´íŠ¸
        old_pattern = r'wr_id=\d+'
        new_url = f'wr_id={wr_id}'
        updated_content = re.sub(old_pattern, new_url, content)
        
        # íŒŒì¼ì— ì €ì¥
        with open('index.html', 'w', encoding='utf-8') as f:
            f.write(updated_content)
        
        print(f"âœ… index.html ì—…ë°ì´íŠ¸ ì™„ë£Œ: wr_id={wr_id}")
        return True
        
    except Exception as e:
        print(f"âŒ index.html ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def git_commit_and_push():
    """ë³€ê²½ì‚¬í•­ì„ Gitì— ì»¤ë°‹í•˜ê³  í‘¸ì‹œ"""
    try:
        # Git ëª…ë ¹ì–´ ì‹¤í–‰
        subprocess.run(['git', 'add', 'index.html'], check=True)
        subprocess.run(['git', 'commit', '-m', f'Auto update latest bulletin - {datetime.now().strftime("%Y-%m-%d %H:%M")}'], check=True)
        subprocess.run(['git', 'push'], check=True)
        
        print("âœ… Git ì»¤ë°‹ ë° í‘¸ì‹œ ì™„ë£Œ")
        return True
        
    except Exception as e:
        print(f"âŒ Git ì‘ì—… ì‹¤íŒ¨: {e}")
        return False

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print(f"ğŸ”„ ìµœì‹  ì£¼ë³´ í™•ì¸ ì‹œì‘: {datetime.now()}")
    
    # ìµœì‹  ì£¼ë³´ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    latest_info = get_latest_bulletin()
    
    if latest_info:
        print(f"ğŸ“‹ ìµœì‹  ì£¼ë³´ ë°œê²¬: wr_id={latest_info['wr_id']}")
        
        # index.html ì—…ë°ì´íŠ¸
        if update_index_html(latest_info['wr_id']):
            # Git ì»¤ë°‹ ë° í‘¸ì‹œ
            if git_commit_and_push():
                print("ğŸ‰ ìë™ ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
            else:
                print("âš ï¸ Git í‘¸ì‹œ ì‹¤íŒ¨")
        else:
            print("âŒ íŒŒì¼ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨")
    else:
        print("âŒ ìµœì‹  ì£¼ë³´ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

if __name__ == "__main__":
    main() 